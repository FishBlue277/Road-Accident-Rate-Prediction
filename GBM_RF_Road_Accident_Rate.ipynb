{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w99x30GORa-E"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jiahe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
        "import warnings\n",
        "import optuna\n",
        "import scipy.stats as st\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "ETobP6N-R0jX",
        "outputId": "aefd88a7-d6a4-4810-8803-8a8e95f997ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (517754, 14)\n",
            "Test shape: (172585, 13)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>road_type</th>\n",
              "      <th>num_lanes</th>\n",
              "      <th>curvature</th>\n",
              "      <th>speed_limit</th>\n",
              "      <th>lighting</th>\n",
              "      <th>weather</th>\n",
              "      <th>road_signs_present</th>\n",
              "      <th>public_road</th>\n",
              "      <th>time_of_day</th>\n",
              "      <th>holiday</th>\n",
              "      <th>school_season</th>\n",
              "      <th>num_reported_accidents</th>\n",
              "      <th>accident_risk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>urban</td>\n",
              "      <td>2</td>\n",
              "      <td>0.06</td>\n",
              "      <td>35</td>\n",
              "      <td>daylight</td>\n",
              "      <td>rainy</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>afternoon</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>urban</td>\n",
              "      <td>4</td>\n",
              "      <td>0.99</td>\n",
              "      <td>35</td>\n",
              "      <td>daylight</td>\n",
              "      <td>clear</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>evening</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>rural</td>\n",
              "      <td>4</td>\n",
              "      <td>0.63</td>\n",
              "      <td>70</td>\n",
              "      <td>dim</td>\n",
              "      <td>clear</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>morning</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>highway</td>\n",
              "      <td>4</td>\n",
              "      <td>0.07</td>\n",
              "      <td>35</td>\n",
              "      <td>dim</td>\n",
              "      <td>rainy</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>morning</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>rural</td>\n",
              "      <td>1</td>\n",
              "      <td>0.58</td>\n",
              "      <td>60</td>\n",
              "      <td>daylight</td>\n",
              "      <td>foggy</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>evening</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id road_type  num_lanes  curvature  speed_limit  lighting weather  \\\n",
              "0   0     urban          2       0.06           35  daylight   rainy   \n",
              "1   1     urban          4       0.99           35  daylight   clear   \n",
              "2   2     rural          4       0.63           70       dim   clear   \n",
              "3   3   highway          4       0.07           35       dim   rainy   \n",
              "4   4     rural          1       0.58           60  daylight   foggy   \n",
              "\n",
              "   road_signs_present  public_road time_of_day  holiday  school_season  \\\n",
              "0               False         True   afternoon    False           True   \n",
              "1                True        False     evening     True           True   \n",
              "2               False         True     morning     True          False   \n",
              "3                True         True     morning    False          False   \n",
              "4               False        False     evening     True          False   \n",
              "\n",
              "   num_reported_accidents  accident_risk  \n",
              "0                       1           0.13  \n",
              "1                       0           0.35  \n",
              "2                       2           0.30  \n",
              "3                       1           0.21  \n",
              "4                       1           0.56  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv(r\"C:\\Users\\jiahe\\OneDrive\\Desktop\\kaggle\\test.csv\")\n",
        "train = pd.read_csv(r\"C:\\Users\\jiahe\\OneDrive\\Desktop\\kaggle\\train.csv\")\n",
        "\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape:\", test.shape)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "TNAxDkyWSUnL",
        "outputId": "38ada3a0-779a-4365-dac7-06a4b63cff26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                    0\n",
              "road_type             0\n",
              "num_lanes             0\n",
              "curvature             0\n",
              "speed_limit           0\n",
              "lighting              0\n",
              "weather               0\n",
              "road_signs_present    0\n",
              "public_road           0\n",
              "time_of_day           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.isnull().sum().sort_values(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_cat = train.copy()\n",
        "test_cat = test.copy()\n",
        "\n",
        "cat_cols = ['road_type', 'lighting', 'weather', 'time_of_day']\n",
        "\n",
        "for col in cat_cols:\n",
        "    categories = pd.Categorical(pd.concat([train_cat[col], test_cat[col]], axis=0)).categories\n",
        "    train_cat[col] = pd.Categorical(train_cat[col], categories=categories)\n",
        "    test_cat[col] = pd.Categorical(test_cat[col], categories=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target encoding: road_type\n",
            "Target encoding: lighting\n",
            "Target encoding: weather\n",
            "Target encoding: time_of_day\n"
          ]
        }
      ],
      "source": [
        "# List of categorical columns to target encode\n",
        "target_encode_cols = ['road_type', 'lighting', 'weather', 'time_of_day']\n",
        "\n",
        "# Initialize KFold for target encoding\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "encoded_features = pd.DataFrame(index=train.index)\n",
        "\n",
        "for col in target_encode_cols:\n",
        "    print(f\"Target encoding: {col}\")\n",
        "    oof = pd.Series(np.nan, index=train.index)\n",
        "\n",
        "    # Create out-of-fold mean for each category\n",
        "    for train_idx, val_idx in kf.split(train):\n",
        "        means = train.iloc[train_idx].groupby(col)['accident_risk'].mean()\n",
        "        oof.iloc[val_idx] = train.iloc[val_idx][col].astype(str).map(means)\n",
        "\n",
        "\n",
        "    encoded_features[col + '_te'] = oof\n",
        "\n",
        "# Add encoded features to train\n",
        "train = pd.concat([train, encoded_features], axis=1)\n",
        "\n",
        "# Apply same encoding (using full-train mean) to test\n",
        "for col in target_encode_cols:\n",
        "    global_mean = train.groupby(col)['accident_risk'].mean()\n",
        "    test[col + '_te'] = test[col].astype(str).map(global_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# === Define baseline analytic function and clipper ===\n",
        "# =====================================================\n",
        "def f_base(X):\n",
        "    \"\"\"Simple analytic approximation of accident risk.\"\"\"\n",
        "    return (\n",
        "        0.3 * X[\"curvature\"]\n",
        "        + 0.2 * (X[\"lighting\"] == \"night\").astype(int)\n",
        "        + 0.1 * (X[\"weather\"] != \"clear\").astype(int)\n",
        "        + 0.2 * (X[\"speed_limit\"] >= 60).astype(int)\n",
        "        + 0.1 * (X[\"num_reported_accidents\"] > 2).astype(int)\n",
        "    )\n",
        "\n",
        "def clip(f, sigma=0.05):\n",
        "    \"\"\"Smoothly clip predictions into [0,1] using truncated normal expectation.\"\"\"\n",
        "    def clip_f(X):\n",
        "        mu = f(X)\n",
        "        a, b = -mu/sigma, (1 - mu)/sigma\n",
        "        Phi_a, Phi_b = st.norm.cdf(a), st.norm.cdf(b)\n",
        "        phi_a, phi_b = st.norm.pdf(a), st.norm.pdf(b)\n",
        "        return mu*(Phi_b - Phi_a) + sigma*(phi_a - phi_b) + 1 - Phi_b\n",
        "    return clip_f\n",
        "\n",
        "# Apply baseline to train and test\n",
        "train[\"y_base\"] = clip(f_base)(train)\n",
        "test[\"y_base\"] = clip(f_base)(test)\n",
        "\n",
        "# Compute residual target\n",
        "train[\"y_resid\"] = train[\"accident_risk\"] - train[\"y_base\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = train_cat.drop(columns=['id', 'accident_risk'])\n",
        "y = train['y_resid']\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003884 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 170\n",
            "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score -0.000177\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's rmse: 0.0562943\tvalid_0's l2: 0.00316905\n",
            "Fold 2\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004519 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 170\n",
            "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score -0.000280\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's rmse: 0.056169\tvalid_0's l2: 0.00315496\n",
            "Fold 3\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004145 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 176\n",
            "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score -0.000147\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[978]\tvalid_0's rmse: 0.0561706\tvalid_0's l2: 0.00315513\n",
            "Fold 4\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004195 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 178\n",
            "[LightGBM] [Info] Number of data points in the train set: 414203, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score -0.000169\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's rmse: 0.0560317\tvalid_0's l2: 0.00313955\n",
            "Fold 5\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004338 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 173\n",
            "[LightGBM] [Info] Number of data points in the train set: 414204, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score -0.000219\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[999]\tvalid_0's rmse: 0.0559621\tvalid_0's l2: 0.00313175\n",
            "✅ Selected 12 / 12 features after multi-fold averaging.\n"
          ]
        }
      ],
      "source": [
        "importances = pd.DataFrame()\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "    print(f\"Fold {fold+1}\")\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    model_fs = LGBMRegressor(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.03,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model_fs.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric='rmse',\n",
        "        callbacks=[early_stopping(100)]\n",
        "    )\n",
        "\n",
        "    fold_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'gain': model_fs.booster_.feature_importance(importance_type='gain'),\n",
        "        'fold': fold + 1\n",
        "    })\n",
        "    importances = pd.concat([importances, fold_importance], axis=0)\n",
        "\n",
        "# Compute feature importance\n",
        "importance_df = (\n",
        "    importances.groupby('feature')['gain']\n",
        "    .mean()\n",
        "    .sort_values(ascending=False)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Filter weak features\n",
        "threshold = importance_df['gain'].median() * 0.1\n",
        "selected_features = importance_df.query('gain > @threshold')['feature'].tolist()\n",
        "\n",
        "print(f\"✅ Selected {len(selected_features)} / {len(X.columns)} features after multi-fold averaging.\")\n",
        "\n",
        "# Reduce the dataset to selected features\n",
        "X = X[selected_features]\n",
        "test_X = test_cat[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:22:33,338] A new study created in memory with name: no-name-87932734-9d99-479e-8b68-123d8632d6d0\n",
            "Best trial: 0. Best value: 0.0561111:   2%|▎         | 1/40 [03:33<2:18:53, 213.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:26:07,014] Trial 0 finished with value: 0.05611105532733551 and parameters: {'learning_rate': 0.011227845563292689, 'num_leaves': 160, 'max_depth': 5, 'subsample': 0.6148754631475817, 'colsample_bytree': 0.8157015353520217, 'reg_alpha': 0.5036573683373882, 'reg_lambda': 0.8200201144051968, 'min_child_samples': 136}. Best is trial 0 with value: 0.05611105532733551.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 1. Best value: 0.0560824:   5%|▌         | 2/40 [10:01<3:20:15, 316.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:32:34,971] Trial 1 finished with value: 0.056082405579342395 and parameters: {'learning_rate': 0.007800643091268933, 'num_leaves': 110, 'max_depth': 9, 'subsample': 0.6309077041052501, 'colsample_bytree': 0.6991487722337137, 'reg_alpha': 0.38476491312188366, 'reg_lambda': 0.7350972883910267, 'min_child_samples': 95}. Best is trial 1 with value: 0.056082405579342395.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 1. Best value: 0.0560824:   8%|▊         | 3/40 [13:18<2:41:25, 261.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:35:51,978] Trial 2 finished with value: 0.05628613217125526 and parameters: {'learning_rate': 0.0069525602131742525, 'num_leaves': 150, 'max_depth': 4, 'subsample': 0.8722168492539175, 'colsample_bytree': 0.7060703724297954, 'reg_alpha': 0.19145654647888644, 'reg_lambda': 0.14157171305084415, 'min_child_samples': 183}. Best is trial 1 with value: 0.056082405579342395.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 1. Best value: 0.0560824:  10%|█         | 4/40 [16:31<2:20:43, 234.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:39:04,793] Trial 3 finished with value: 0.05623694405589531 and parameters: {'learning_rate': 0.008877659358457295, 'num_leaves': 57, 'max_depth': 4, 'subsample': 0.6726010774556109, 'colsample_bytree': 0.626819192738186, 'reg_alpha': 0.1625601914654482, 'reg_lambda': 0.2658756523739906, 'min_child_samples': 43}. Best is trial 1 with value: 0.056082405579342395.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 1. Best value: 0.0560824:  12%|█▎        | 5/40 [22:32<2:43:31, 280.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:45:06,289] Trial 4 finished with value: 0.05628310072903429 and parameters: {'learning_rate': 0.01763743225501276, 'num_leaves': 110, 'max_depth': 9, 'subsample': 0.7484038795390853, 'colsample_bytree': 0.7797848378926759, 'reg_alpha': 0.13446162681014684, 'reg_lambda': 0.3093872133400102, 'min_child_samples': 164}. Best is trial 1 with value: 0.056082405579342395.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 1. Best value: 0.0560824:  15%|█▌        | 6/40 [22:33<1:44:52, 185.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:45:06,497] Trial 5 pruned. Trial was pruned at iteration 1.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 1. Best value: 0.0560824:  18%|█▊        | 7/40 [22:33<1:08:33, 124.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:45:06,717] Trial 6 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 7. Best value: 0.0560793:  20%|██        | 8/40 [25:39<1:16:57, 144.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:48:13,097] Trial 7 finished with value: 0.056079305093674 and parameters: {'learning_rate': 0.021873246968358608, 'num_leaves': 194, 'max_depth': 6, 'subsample': 0.6373587629306415, 'colsample_bytree': 0.7030328686526451, 'reg_alpha': 0.7417084898469293, 'reg_lambda': 0.5354200095353459, 'min_child_samples': 54}. Best is trial 7 with value: 0.056079305093674.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 7. Best value: 0.0560793:  22%|██▎       | 9/40 [31:16<1:45:37, 204.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:53:49,741] Trial 8 finished with value: 0.0562272234181224 and parameters: {'learning_rate': 0.03342885172466514, 'num_leaves': 157, 'max_depth': 6, 'subsample': 0.8339671525340715, 'colsample_bytree': 0.760361617485468, 'reg_alpha': 0.08816395173626923, 'reg_lambda': 0.8533672828240976, 'min_child_samples': 199}. Best is trial 7 with value: 0.056079305093674.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 7. Best value: 0.0560793:  25%|██▌       | 10/40 [31:16<1:10:41, 141.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:53:49,956] Trial 9 pruned. Trial was pruned at iteration 1.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.0560763:  28%|██▊       | 11/40 [33:34<1:07:46, 140.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:56:07,556] Trial 10 finished with value: 0.05607631946058052 and parameters: {'learning_rate': 0.04897534145547061, 'num_leaves': 199, 'max_depth': 6, 'subsample': 0.7120036561958804, 'colsample_bytree': 0.894565042418416, 'reg_alpha': 0.8638830691549946, 'reg_lambda': 0.5505076357187897, 'min_child_samples': 74}. Best is trial 10 with value: 0.05607631946058052.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 10. Best value: 0.0560763:  30%|███       | 12/40 [35:53<1:05:16, 139.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 16:58:26,634] Trial 11 finished with value: 0.05608256614946387 and parameters: {'learning_rate': 0.04995538153235129, 'num_leaves': 196, 'max_depth': 6, 'subsample': 0.6991760923188756, 'colsample_bytree': 0.8932425963584673, 'reg_alpha': 0.8157131594526199, 'reg_lambda': 0.5758462976810751, 'min_child_samples': 70}. Best is trial 10 with value: 0.05607631946058052.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 12. Best value: 0.0560751:  32%|███▎      | 13/40 [38:35<1:06:01, 146.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:01:09,167] Trial 12 finished with value: 0.05607513772281035 and parameters: {'learning_rate': 0.02622880525147948, 'num_leaves': 200, 'max_depth': 6, 'subsample': 0.7156247258141631, 'colsample_bytree': 0.8751424954541013, 'reg_alpha': 0.7042540288450213, 'reg_lambda': 0.5236352097848129, 'min_child_samples': 70}. Best is trial 12 with value: 0.05607513772281035.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 13. Best value: 0.0560706:  35%|███▌      | 14/40 [41:08<1:04:19, 148.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:03:41,604] Trial 13 finished with value: 0.0560706031281051 and parameters: {'learning_rate': 0.049914586388583114, 'num_leaves': 183, 'max_depth': 7, 'subsample': 0.7488295003652871, 'colsample_bytree': 0.8837256300228906, 'reg_alpha': 0.6631298102231494, 'reg_lambda': 0.41618551441600476, 'min_child_samples': 83}. Best is trial 13 with value: 0.0560706031281051.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 13. Best value: 0.0560706:  38%|███▊      | 15/40 [41:20<44:43, 107.34s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:03:53,646] Trial 14 pruned. Trial was pruned at iteration 3315.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  40%|████      | 16/40 [44:03<49:36, 124.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:06:36,413] Trial 15 finished with value: 0.05606987750438096 and parameters: {'learning_rate': 0.03464068597164972, 'num_leaves': 180, 'max_depth': 7, 'subsample': 0.7797064488266761, 'colsample_bytree': 0.8482114200300792, 'reg_alpha': 0.6399945734636989, 'reg_lambda': 0.697191602993814, 'min_child_samples': 86}. Best is trial 15 with value: 0.05606987750438096.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  42%|████▎     | 17/40 [47:00<53:39, 139.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:09:33,440] Trial 16 finished with value: 0.05608689593845763 and parameters: {'learning_rate': 0.03775632259847021, 'num_leaves': 178, 'max_depth': 8, 'subsample': 0.8284317228152213, 'colsample_bytree': 0.8462083912748211, 'reg_alpha': 0.5939918591144427, 'reg_lambda': 0.9882305115968197, 'min_child_samples': 124}. Best is trial 15 with value: 0.05606987750438096.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  45%|████▌     | 18/40 [49:51<54:44, 149.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:12:24,419] Trial 17 finished with value: 0.056085435754402044 and parameters: {'learning_rate': 0.03909883115170538, 'num_leaves': 138, 'max_depth': 8, 'subsample': 0.7806309193394677, 'colsample_bytree': 0.8049153036188361, 'reg_alpha': 0.5479603958603676, 'reg_lambda': 0.0067481493751122, 'min_child_samples': 89}. Best is trial 15 with value: 0.05606987750438096.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  48%|████▊     | 19/40 [49:51<36:34, 104.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:12:24,631] Trial 18 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  50%|█████     | 20/40 [49:51<24:23, 73.20s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:12:24,848] Trial 19 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  52%|█████▎    | 21/40 [52:45<32:44, 103.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:15:18,688] Trial 20 finished with value: 0.05624854556282235 and parameters: {'learning_rate': 0.041956555712825666, 'num_leaves': 184, 'max_depth': 9, 'subsample': 0.8284047575862967, 'colsample_bytree': 0.8046259820406203, 'reg_alpha': 0.28144885249081353, 'reg_lambda': 0.663823646071847, 'min_child_samples': 21}. Best is trial 15 with value: 0.05606987750438096.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  55%|█████▌    | 22/40 [52:45<21:43, 72.44s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:15:18,902] Trial 21 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  57%|█████▊    | 23/40 [52:45<14:23, 50.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:15:19,122] Trial 22 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  60%|██████    | 24/40 [52:46<09:29, 35.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:15:19,364] Trial 23 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  62%|██████▎   | 25/40 [56:15<21:54, 87.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:18:48,470] Trial 24 finished with value: 0.05610118612026278 and parameters: {'learning_rate': 0.042389737868297236, 'num_leaves': 199, 'max_depth': 8, 'subsample': 0.7666059139693436, 'colsample_bytree': 0.8203284636809091, 'reg_alpha': 0.47052406993365614, 'reg_lambda': 0.7868876184738549, 'min_child_samples': 89}. Best is trial 15 with value: 0.05606987750438096.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  65%|██████▌   | 26/40 [56:15<14:19, 61.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:18:48,690] Trial 25 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  68%|██████▊   | 27/40 [56:15<09:19, 43.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:18:48,914] Trial 26 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  70%|███████   | 28/40 [56:15<06:02, 30.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:18:49,160] Trial 27 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  72%|███████▎  | 29/40 [56:16<03:53, 21.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:18:49,406] Trial 28 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  75%|███████▌  | 30/40 [59:55<13:27, 80.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:22:28,935] Trial 29 finished with value: 0.05610731531770012 and parameters: {'learning_rate': 0.044251547420648005, 'num_leaves': 163, 'max_depth': 8, 'subsample': 0.8124394733280733, 'colsample_bytree': 0.8206011238608584, 'reg_alpha': 0.453867347830229, 'reg_lambda': 0.6280675007602834, 'min_child_samples': 81}. Best is trial 15 with value: 0.05606987750438096.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  78%|███████▊  | 31/40 [59:55<08:29, 56.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:22:29,151] Trial 30 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  80%|████████  | 32/40 [59:56<05:18, 39.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:22:29,866] Trial 31 pruned. Trial was pruned at iteration 92.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 15. Best value: 0.0560699:  82%|████████▎ | 33/40 [59:57<03:16, 28.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:22:30,555] Trial 32 pruned. Trial was pruned at iteration 70.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 33. Best value: 0.0560662:  85%|████████▌ | 34/40 [1:02:18<06:12, 62.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:24:52,041] Trial 33 finished with value: 0.056066197954237916 and parameters: {'learning_rate': 0.0495012872776267, 'num_leaves': 200, 'max_depth': 7, 'subsample': 0.6631789958203984, 'colsample_bytree': 0.8944650712936875, 'reg_alpha': 0.7832768442356759, 'reg_lambda': 0.7373495662419753, 'min_child_samples': 95}. Best is trial 33 with value: 0.056066197954237916.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 33. Best value: 0.0560662:  88%|████████▊ | 35/40 [1:02:18<03:37, 43.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:24:52,259] Trial 34 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 33. Best value: 0.0560662:  90%|█████████ | 36/40 [1:02:19<02:02, 30.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:24:52,488] Trial 35 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 33. Best value: 0.0560662:  92%|█████████▎| 37/40 [1:02:19<01:04, 21.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:24:52,727] Trial 36 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 33. Best value: 0.0560662:  95%|█████████▌| 38/40 [1:02:19<00:30, 15.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:24:52,971] Trial 37 pruned. Trial was pruned at iteration 0.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 33. Best value: 0.0560662:  98%|█████████▊| 39/40 [1:02:19<00:10, 10.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:24:53,211] Trial 38 pruned. Trial was pruned at iteration 1.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Best trial: 33. Best value: 0.0560662: 100%|██████████| 40/40 [1:04:53<00:00, 97.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:27:27,040] Trial 39 finished with value: 0.056071524739663495 and parameters: {'learning_rate': 0.047957761142369146, 'num_leaves': 95, 'max_depth': 7, 'subsample': 0.647913706926178, 'colsample_bytree': 0.8851791951504548, 'reg_alpha': 0.5852564294330658, 'reg_lambda': 0.19413428397755528, 'min_child_samples': 49}. Best is trial 33 with value: 0.056066197954237916.\n",
            "Best RMSE: 0.056066197954237916\n",
            "Best Params: {'learning_rate': 0.0495012872776267, 'num_leaves': 200, 'max_depth': 7, 'subsample': 0.6631789958203984, 'colsample_bytree': 0.8944650712936875, 'reg_alpha': 0.7832768442356759, 'reg_lambda': 0.7373495662419753, 'min_child_samples': 95}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": 8000,\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.05, log=True),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 50, 200),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 20, 200),\n",
        "        \"random_state\": 42,\n",
        "        \"n_jobs\": -1,\n",
        "        \"verbosity\": -1\n",
        "    }\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    rmse_scores = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        model = LGBMRegressor(**params)\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            eval_metric=\"rmse\",\n",
        "            callbacks=[optuna.integration.LightGBMPruningCallback(trial, \"rmse\")]\n",
        "        )\n",
        "        preds = model.predict(X_val)\n",
        "        mse = mean_squared_error(y_val, preds)\n",
        "        rmse = np.sqrt(mse)\n",
        "        rmse_scores.append(rmse)\n",
        "        \n",
        "    return np.mean(rmse_scores)\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=40, show_progress_bar=True)\n",
        "\n",
        "print(\"Best RMSE:\", study.best_value)\n",
        "print(\"Best Params:\", study.best_params)\n",
        "\n",
        "best_params = study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up 8-Fold CV\n",
        "kf = KFold(n_splits=8, shuffle=True, random_state=42)\n",
        "rmse_scores = []\n",
        "test_X = test_cat.drop(columns=['id'])\n",
        "test_preds_all = np.zeros(len(test_X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Fold 1 / 8 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[770]\tvalid_0's rmse: 0.0559701\tvalid_0's l2: 0.00313265\n",
            "Fold 1 RMSE: 0.05598\n",
            "\n",
            "===== Fold 2 / 8 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[778]\tvalid_0's rmse: 0.0564715\tvalid_0's l2: 0.00318903\n",
            "Fold 2 RMSE: 0.05646\n",
            "\n",
            "===== Fold 3 / 8 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[911]\tvalid_0's rmse: 0.0561182\tvalid_0's l2: 0.00314926\n",
            "Fold 3 RMSE: 0.05613\n",
            "\n",
            "===== Fold 4 / 8 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[632]\tvalid_0's rmse: 0.0561116\tvalid_0's l2: 0.00314852\n",
            "Fold 4 RMSE: 0.05614\n",
            "\n",
            "===== Fold 5 / 8 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[894]\tvalid_0's rmse: 0.0560333\tvalid_0's l2: 0.00313973\n",
            "Fold 5 RMSE: 0.05602\n",
            "\n",
            "===== Fold 6 / 8 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1006]\tvalid_0's rmse: 0.0559642\tvalid_0's l2: 0.00313199\n",
            "Fold 6 RMSE: 0.05597\n",
            "\n",
            "===== Fold 7 / 8 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[841]\tvalid_0's rmse: 0.0557972\tvalid_0's l2: 0.00311332\n",
            "Fold 7 RMSE: 0.05579\n",
            "\n",
            "===== Fold 8 / 8 =====\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[877]\tvalid_0's rmse: 0.0559438\tvalid_0's l2: 0.0031297\n",
            "Fold 8 RMSE: 0.05593\n",
            "\n",
            "============================\n",
            "Average RMSE (equal 0.5 blend): 0.05605\n",
            "============================\n"
          ]
        }
      ],
      "source": [
        "# store out-of-fold preds for later alpha tuning\n",
        "oof_lgb = np.zeros(len(X))\n",
        "oof_y = y.values.copy()\n",
        "oof_rf = np.zeros(len(X))\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "    print(f\"\\n===== Fold {fold + 1} / {kf.n_splits} =====\")\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    # Align columns\n",
        "    X_val = X_val[X_train.columns]\n",
        "    test_X = test_X[X_train.columns]\n",
        "\n",
        "    # === LightGBM model (tuned) ===\n",
        "    model_lgb = LGBMRegressor(\n",
        "        **study.best_params,\n",
        "        n_estimators=12000,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbosity=-1\n",
        "    )\n",
        "\n",
        "    model_lgb.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric='rmse',\n",
        "        callbacks=[early_stopping(200), log_evaluation(0)]\n",
        "    )\n",
        "    \n",
        "    preds_lgb = model_lgb.predict(X_val)\n",
        "    oof_lgb[val_idx] = preds_lgb\n",
        "\n",
        "    # === Random Forest model ===\n",
        "    # === Prepare numeric data for Random Forest ===\n",
        "    X_train_rf = pd.get_dummies(X_train, drop_first=True)\n",
        "    X_val_rf   = pd.get_dummies(X_val, drop_first=True)\n",
        "\n",
        "    # Align columns (since get_dummies may create mismatched columns)\n",
        "    X_train_rf, X_val_rf = X_train_rf.align(X_val_rf, join='left', axis=1, fill_value=0)\n",
        "\n",
        "    model_rf = RandomForestRegressor(\n",
        "        n_estimators=500,\n",
        "        max_depth=15,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    model_rf.fit(X_train_rf, y_train)\n",
        "    preds_rf = model_rf.predict(X_val_rf)\n",
        "    oof_rf[val_idx] = preds_rf\n",
        "\n",
        "    # temporary equal blend for monitoring\n",
        "    val_preds = 0.5 * preds_lgb + 0.5 * preds_rf\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
        "    rmse_scores.append(rmse)\n",
        "    print(f\"Fold {fold + 1} RMSE: {rmse:.5f}\")\n",
        "\n",
        "    # === Predict on test and accumulate (equal blend for now) ===\n",
        "    test_X_rf = pd.get_dummies(test_X, drop_first=True)\n",
        "    test_X_rf = test_X_rf.reindex(columns=X_train_rf.columns, fill_value=0)\n",
        "\n",
        "    test_pred_lgb = model_lgb.predict(test_X)\n",
        "    test_pred_rf = model_rf.predict(test_X_rf)\n",
        "    test_preds_all += (0.5 * test_pred_lgb + 0.5 * test_pred_rf) / kf.n_splits\n",
        "\n",
        "# Display preliminary CV RMSE\n",
        "print(\"\\n============================\")\n",
        "print(f\"Average RMSE (equal 0.5 blend): {np.mean(rmse_scores):.5f}\")\n",
        "print(\"============================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Overall OOF correlation between LGBM and RF: 0.9133\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "overall_corr = np.corrcoef(oof_lgb, oof_rf)[0, 1]\n",
        "print(f\"\\nOverall OOF correlation between LGBM and RF: {overall_corr:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.kdeplot(x=oof_lgb, y=oof_rf, fill=True, cmap='viridis')\n",
        "plt.title(f'OOF Prediction Correlation: {overall_corr:.4f}')\n",
        "plt.xlabel('LGBM OOF Predictions')\n",
        "plt.ylabel('RF OOF Predictions')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-28 17:38:53,559] A new study created in memory with name: no-name-64a6f7ed-787a-4e9b-a172-6748a06690a6\n",
            "[I 2025-10-28 17:38:53,568] Trial 0 finished with value: 0.056023550648007917 and parameters: {'alpha': 0.8238597794839118}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,576] Trial 1 finished with value: 0.05607626045509812 and parameters: {'alpha': 0.4196939460636917}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,583] Trial 2 finished with value: 0.05602754009508907 and parameters: {'alpha': 0.6382116761793827}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,591] Trial 3 finished with value: 0.05602996910579337 and parameters: {'alpha': 0.6185997480619531}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,598] Trial 4 finished with value: 0.05613917197320615 and parameters: {'alpha': 0.2656107245074466}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,606] Trial 5 finished with value: 0.056078414833481235 and parameters: {'alpha': 0.41326191443584526}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,614] Trial 6 finished with value: 0.05624299014194338 and parameters: {'alpha': 0.08481135190152622}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,621] Trial 7 finished with value: 0.056023695363109714 and parameters: {'alpha': 0.8258668003094434}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,629] Trial 8 finished with value: 0.056043322928042365 and parameters: {'alpha': 0.5410824773411291}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,638] Trial 9 finished with value: 0.056031574211539655 and parameters: {'alpha': 0.6070831219604089}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,647] Trial 10 finished with value: 0.05604344407342711 and parameters: {'alpha': 0.964649737086899}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,656] Trial 11 finished with value: 0.05603217758324752 and parameters: {'alpha': 0.9021756032881895}. Best is trial 0 with value: 0.056023550648007917.\n",
            "[I 2025-10-28 17:38:53,665] Trial 12 finished with value: 0.05602164441906997 and parameters: {'alpha': 0.7880620472630827}. Best is trial 12 with value: 0.05602164441906997.\n",
            "[I 2025-10-28 17:38:53,674] Trial 13 finished with value: 0.056021379217234435 and parameters: {'alpha': 0.7795481909648871}. Best is trial 13 with value: 0.056021379217234435.\n",
            "[I 2025-10-28 17:38:53,683] Trial 14 finished with value: 0.056021016987206906 and parameters: {'alpha': 0.753622932721268}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,692] Trial 15 finished with value: 0.05602102822425804 and parameters: {'alpha': 0.7574391412029322}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,701] Trial 16 finished with value: 0.05602298763603306 and parameters: {'alpha': 0.6897136452990807}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,711] Trial 17 finished with value: 0.056044379618573906 and parameters: {'alpha': 0.9690286003138413}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,720] Trial 18 finished with value: 0.056021465060026344 and parameters: {'alpha': 0.7225888086219568}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,729] Trial 19 finished with value: 0.056040393873384775 and parameters: {'alpha': 0.5554592979925724}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,739] Trial 20 finished with value: 0.05628663743321445 and parameters: {'alpha': 0.0219612226707383}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,747] Trial 21 finished with value: 0.05602128752819495 and parameters: {'alpha': 0.7292663065170955}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,756] Trial 22 finished with value: 0.056027755995728436 and parameters: {'alpha': 0.8688240963049114}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,765] Trial 23 finished with value: 0.05602200016593173 and parameters: {'alpha': 0.7081690417361151}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,775] Trial 24 finished with value: 0.05607470905684985 and parameters: {'alpha': 0.4244036529237889}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,785] Trial 25 finished with value: 0.05602177335661687 and parameters: {'alpha': 0.7136237281272948}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,793] Trial 26 finished with value: 0.05603185486363048 and parameters: {'alpha': 0.8999967698626832}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,803] Trial 27 finished with value: 0.05612624131400768 and parameters: {'alpha': 0.29305542972111587}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,811] Trial 28 finished with value: 0.05605084298679302 and parameters: {'alpha': 0.5080086652612986}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,821] Trial 29 finished with value: 0.056021733448302836 and parameters: {'alpha': 0.7904939543711695}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,830] Trial 30 finished with value: 0.056025084234492775 and parameters: {'alpha': 0.8428885234049093}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,840] Trial 31 finished with value: 0.05602105202705861 and parameters: {'alpha': 0.7610255942017182}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,848] Trial 32 finished with value: 0.05602102757522006 and parameters: {'alpha': 0.7573033674206265}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,858] Trial 33 finished with value: 0.05602758015893069 and parameters: {'alpha': 0.6378610090655052}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,869] Trial 34 finished with value: 0.056024457018020994 and parameters: {'alpha': 0.6695240209612918}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,880] Trial 35 finished with value: 0.056021149665443 and parameters: {'alpha': 0.7689223071114132}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,890] Trial 36 finished with value: 0.05603485195448736 and parameters: {'alpha': 0.5860197740894962}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,899] Trial 37 finished with value: 0.0560499603913105 and parameters: {'alpha': 0.9935032393960849}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,908] Trial 38 finished with value: 0.05603438787019154 and parameters: {'alpha': 0.9163211722323086}. Best is trial 14 with value: 0.056021016987206906.\n",
            "[I 2025-10-28 17:38:53,917] Trial 39 finished with value: 0.056067636701569314 and parameters: {'alpha': 0.4467896961223946}. Best is trial 14 with value: 0.056021016987206906.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Best alpha for blending: 0.7536\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# === Tune alpha weight between LGBM & RF ===\n",
        "# =====================================================\n",
        "def objective_alpha(trial):\n",
        "    alpha = trial.suggest_float(\"alpha\", 0.0, 1.0)\n",
        "    blend = alpha * oof_lgb + (1 - alpha) * oof_rf\n",
        "    return np.sqrt(mean_squared_error(oof_y, blend))\n",
        "\n",
        "study_alpha = optuna.create_study(direction=\"minimize\")\n",
        "study_alpha.optimize(objective_alpha, n_trials=40)\n",
        "best_alpha = study_alpha.best_params[\"alpha\"]\n",
        "print(f\"✅ Best alpha for blending: {best_alpha:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final blended OOF RMSE: 0.05602\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# === Final blending using best alpha ===\n",
        "# =====================================================\n",
        "# recompute CV RMSE using best alpha\n",
        "final_oof = best_alpha * oof_lgb + (1 - best_alpha) * oof_rf\n",
        "final_rmse = np.sqrt(mean_squared_error(oof_y, final_oof))\n",
        "print(f\"Final blended OOF RMSE: {final_rmse:.5f}\")\n",
        "\n",
        "# re-blend test predictions using alpha\n",
        "test_pred_final = best_alpha * test_pred_lgb + (1 - best_alpha) * test_pred_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Ridge Regression Meta-Blender ---\n",
            "Ridge-blend OOF RMSE: 0.05602\n",
            "Ridge coefficients (LGBM, RF): [0.75033773 0.24743416]\n",
            "Optuna alpha-blend OOF RMSE: 0.05602\n",
            "✅ Ridge performs slightly better; using Ridge predictions.\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# === Ridge regression meta-blender ===\n",
        "# =====================================================\n",
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "print(\"\\n--- Ridge Regression Meta-Blender ---\")\n",
        "\n",
        "meta_X = np.vstack([oof_lgb, oof_rf]).T\n",
        "meta_y = oof_y\n",
        "\n",
        "ridge = RidgeCV(alphas=[1e-4, 1e-3, 1e-2, 1e-1, 1, 10])\n",
        "ridge.fit(meta_X, meta_y)\n",
        "ridge_oof = ridge.predict(meta_X)\n",
        "ridge_rmse = np.sqrt(mean_squared_error(meta_y, ridge_oof))\n",
        "print(f\"Ridge-blend OOF RMSE: {ridge_rmse:.5f}\")\n",
        "print(\"Ridge coefficients (LGBM, RF):\", ridge.coef_)\n",
        "\n",
        "# Predict on test set using same meta model\n",
        "test_meta_X = np.vstack([test_pred_lgb, test_pred_rf]).T\n",
        "test_pred_ridge = ridge.predict(test_meta_X)\n",
        "\n",
        "# Optionally compare with Optuna alpha blend\n",
        "print(f\"Optuna alpha-blend OOF RMSE: {final_rmse:.5f}\")\n",
        "if ridge_rmse < final_rmse:\n",
        "    print(\"✅ Ridge performs slightly better; using Ridge predictions.\")\n",
        "    test_pred_final = test_pred_ridge\n",
        "else:\n",
        "    print(\"ℹ️ Keeping Optuna alpha blend as final.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved OOF predictions to oof_lgb_rf.csv\n",
            "✅ Saved test predictions to test_lgb_rf.csv\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# === Save OOF and test predictions for stacking ===\n",
        "# =====================================================\n",
        "\n",
        "# Save OOF predictions for meta-learning later\n",
        "oof_df = pd.DataFrame({\n",
        "    'id': train_cat['id'],\n",
        "    'oof_lgb': oof_lgb,\n",
        "    'oof_rf': oof_rf,\n",
        "    'oof_blend': final_oof,\n",
        "})\n",
        "\n",
        "# Map y_base and accident_risk by ID (safe alignment)\n",
        "ybase_map = dict(zip(train['id'], train['y_base']))\n",
        "true_map = dict(zip(train['id'], train['accident_risk']))\n",
        "\n",
        "# Add baseline offset to all model OOF predictions\n",
        "for col in [\"oof_lgb\", \"oof_rf\", \"oof_blend\"]:\n",
        "    oof_df[col] = oof_df[col] + oof_df[\"id\"].map(ybase_map)\n",
        "\n",
        "# Replace label with full-scale accident_risk\n",
        "oof_df[\"y_true\"] = oof_df[\"id\"].map(true_map)\n",
        "\n",
        "oof_df.to_csv('oof_lgb_rf.csv', index=False)\n",
        "print(\"✅ Saved OOF predictions to oof_lgb_rf.csv\")\n",
        "\n",
        "# Save test predictions (for later external blending)\n",
        "test_stack_df = pd.DataFrame({\n",
        "    'id': test_cat['id'],\n",
        "    'test_lgb': test_pred_lgb,\n",
        "    'test_rf': test_pred_rf,\n",
        "    'test_blend': test_pred_final\n",
        "})\n",
        "\n",
        "test_ybase_map = dict(zip(test_cat[\"id\"], test[\"y_base\"]))\n",
        "for col in [\"test_lgb\", \"test_rf\", \"test_blend\"]:\n",
        "    test_stack_df[col] = test_stack_df[col] + test_stack_df[\"id\"].map(test_ybase_map)\n",
        "\n",
        "test_stack_df.to_csv('test_lgb_rf.csv', index=False)\n",
        "print(\"✅ Saved test predictions to test_lgb_rf.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ submission_rfblend.csv ready for Kaggle upload!\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# === Save final blended predictions ===\n",
        "# =====================================================\n",
        "\n",
        "# Combine optimized test predictions with baseline offset\n",
        "final_preds = test_pred_final + test[\"y_base\"]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_cat['id'],\n",
        "    'accident_risk': final_preds\n",
        "})\n",
        "\n",
        "submission.to_csv('submission_rfblend.csv', index=False)\n",
        "print(\"✅ submission_rfblend.csv ready for Kaggle upload!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
